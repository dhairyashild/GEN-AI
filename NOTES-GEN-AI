

What is Artificial Intelligence?
AI is tech that mimics human smarts to think, learn, and solve problems.

What is Machine Learning?
ML is AI where computers learn patterns from data without explicit programming.

What is Deep Learning?
Deep learning uses layered neural networks to learn complex features automatically.

What is a Neural Network?
A neural network is brain-inspired connected nodes processing data.

What is Supervised Learning?
Supervised learning trains on labeled data to predict outcomes.

What is Unsupervised Learning?
Unsupervised learning discovers patterns in unlabeled data.

What is Reinforcement Learning?
Reinforcement learning improves via trial-and-error rewards.

What is Overfitting?
Overfitting memorizes training data but flops on new data.

What is Gradient Descent?
Gradient descent tweaks weights step-by-step to cut errors.





##################################################################################################################################3
GEEKS NOTES

LLM: Large Language Model, an AI trained on vast text data to understand and generate human-like language.

Gen AI: Generative AI creates new content like text, images, or code from learned data patterns.

LangChain: Framework that links language models with tools to build AI apps.
#PYTHON ENV SET UP
uv init ai-project                             # Creates folder 'ai-project' with pyproject.toml and hello.py
cd ai-project &&             
uv python pin 3.12                             # Creates .python-version file to fix the project to Python 3.12
uv add openai langchain python-dotenv          # Creates .venv/ and uv.lock; installs GenAI libraries instantly
echo "OPENAI_API_KEY=sk-your-key-here" > .env   # Creates .env file to securely store your API keys
ls -a


virtauenv env                          ## only this command creates below all files 
source venv/scripts/activate            # it activates env only
pip freeze
pip  install python-decouple
pip  install langchain

virtualenv venv creates this folder structure:
venv/
├── pyvenv.cfg          # Config: points to base Python
├── Scripts/            # Windows executables
│   ├── python.exe      # Isolated Python
│   ├── pip.exe         # Isolated pip
│   ├── activate.bat    # CMD activation
│   └── activate.ps1    # PowerShell activation
├── Include/            # C headers (empty initially)
└── Lib/                # Isolated packages
    └── site-packages/  # Empty package dir

token = basic word /subword that  LLMs can process.
-Token: Basic text unit (word/part); ~4 chars =(LOVE)= 1 token, or 0.75 words per token.
-change as per model like for GPT3 = 1 token = 5 char= (HELLOW)

#########################################################################################################################################
### YOUTUBE GEEKS VID =LLMs and Chat Models with LangChain Python   ###
LINK ---
https://docs.langchain.com/oss/python/langchain/models#huggingface
SELECT -----HuggingFace
## GPT INFO init_chat_model vs Model Class - Simple Use Production Pick==init_chat_model - Switch providers without code changes.
SELECT --- Model Class----> COPY CODE LIKE BELOW 



import os
from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint

os.environ["HUGGINGFACEHUB_API_TOKEN"] = "hf_..."       # WE DONT NEED THIS AS WE CALL      decouple + config TO CALL KEY NAME

llm = HuggingFaceEndpoint(
    repo_id="microsoft/Phi-3-mini-4k-instruct",    # CHANGE  MODELS LIKE   HuggingFaceH4/zephyr-7b-beta   / mistralai/Mistral-7B-Instruct-v0.2 / meta-llama/Meta-Llama-3-8B-Instruct
    temperature=0.7,
    max_new_tokens=1024,  # ✅ Fixed: max_new_tokens not max_length     # max_new_tokens=1024,             REPLACE THIS INTO CODE AND REMOVE max_length=1024,
)
model = ChatHuggingFace(llm=llm)

responce=model.invoke                       # after this add what u want                    
 print(responce.content) 
--------------------------------------------------------------------------
## GPT INFO init_chat_model vs Model Class - Simple Use Production Pick==init_chat_model - Switch providers without code changes.
- init_chat_model==One line loads any model: model = init_chat_model("gpt-4o")  
- Model Class===Two steps needed: llm = HuggingFaceEndpoint(...) then model = ChatHuggingFace(llm)

#########################################################################################################################################






































































































